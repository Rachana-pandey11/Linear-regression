# -*- coding: utf-8 -*-
"""ML Lab - 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVdi9X4Vr4uFmi_bnhAmvG0mkjFNKDIi

Aim: Write a program to implement **linear regression** without using python libraries
"""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error 
import matplotlib.pyplot as plt 
plt.rcParams['figure.figsize']= (10.0,10.0)

from google.colab import files
uploaded = files.upload()

data = pd.read_csv('student.csv')
print(data.shape)
math = data['Math'].values
read = data['Reading'].values
write = data['Writing'].values

m = len(math)
x0 = np.ones(m)
X = np.array([x0, math, read]).T

B = np.array([0,0,0])
Y = np.array(write)
alpha = 0.0001

def cost_function(X, Y, B):
  m = len(Y)
  J = np.sum((X.dot(B) - Y)**2)/(2*m)
  return J

initial_cost = cost_function(X, Y, B)
print(initial_cost)

def gradient_descent(X, Y, B, alpha, iterations):
  cost_history = [0] *iterations
  m = len(Y)
  for iterations in range(iterations):
    h = X.dot(B)
    loss = h-Y
    gradient = X.T.dot(loss)/m
    B = B - alpha * gradient
    cost = cost_function(X, Y, B)
    cost_history[iterations] = cost

  return B, cost_history

newB, cost_history = gradient_descent(X,Y,B, alpha, 10000)

print(newB)
print(cost_history[-1])

Y_pred = X.dot(newB)

rmse = np.sqrt(mean_squared_error(Y, Y_pred))
print("rmse=", rmse)

def r2_score(Y,Y_pred):
  mean_Y = np.mean(Y)
  ss_tot = sum((Y - mean_Y)** 2)
  ss_res = sum((Y - Y_pred)** 2)
  r2 = 1 - (ss_res / ss_tot)
  return r2

print("R2 score: ", r2_score(Y, Y_pred))